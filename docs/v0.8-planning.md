# v0.8 Planning: Expanded Jewel Optimization & Better Mastery Handling

## Implementation Status (Updated January 2025)

| Stream | Tasks | Status | Tests |
|--------|-------|--------|-------|
| **A** Mastery Calculator | A1-A3 | **COMPLETE** | 30 pass |
| **B** Radius Infrastructure | B1-B3 | **COMPLETE** | 27 pass |
| **C** Timeless Jewels | C1-C3 | **COMPLETE** | 36 pass |
| **D** Build Context | D1 | **COMPLETE** | 30 pass |
| **E** Cluster Optimization | E1-E3 | **COMPLETE** | 33 pass |
| **Integration** | I1-I4 | **PENDING** | - |

**Next Steps**: Integration tasks I1-I4 to wire new modules into main optimizers.
See `DEVELOPMENT.md` for implementation details and key interfaces.

---

## Executive Summary

This document outlines the comprehensive plan for v0.8, which focuses on two major areas:
1. **Expanded Jewel Optimization** - Moving beyond socket protection to active jewel-aware optimization
2. **Better Mastery Handling** - Replacing heuristic-based selection with calculator-driven evaluation

---

## Part 1: Current State Analysis

### 1.1 Jewel System - What Works

| Component | Status | Location |
|-----------|--------|----------|
| Timeless jewel parsing (seed, variant, legion) | Working | `src/pob/jewel/timeless.py` |
| Cluster jewel parsing (size, notables, nodes) | Working | `src/pob/jewel/cluster.py` |
| Unique jewel recognition (50+ types) | Working | `src/pob/jewel/unique.py` |
| Protected nodes (sockets + cluster subgraphs) | Working | `src/pob/jewel/registry.py` |
| Socket discovery & classification | Working | `src/pob/jewel/socket_optimizer.py` |
| Jewel swap/move mutations (genetic) | Working | `src/optimizer/genetic_optimizer.py` |
| Jewel swap candidates (greedy) | Working | `src/optimizer/tree_optimizer.py` |

### 1.2 Jewel System - What's Missing

| Gap | Impact | Priority |
|-----|--------|----------|
| No timeless jewel modifier calculation | Can't optimize nodes in radius | HIGH |
| No radius jewel analysis (Thread of Hope, etc.) | Missing pathing bypass optimization | HIGH |
| No cluster notable selection optimization | Can't optimize within cluster subgraphs | MEDIUM |
| No rare/magic jewel support | Can't recommend jewel affixes | LOW |
| No abyss jewel support | Missing abyss socket handling | LOW |
| Jewel placement doesn't consider radius effects | Suboptimal unique jewel placement | MEDIUM |

### 1.3 Mastery System - What Works

| Component | Status | Location |
|-----------|--------|----------|
| Mastery database loading from PoB | Working | `src/pob/mastery_optimizer.py:313-392` |
| Mastery effect parsing (4-6 options per node) | Working | `src/pob/mastery_optimizer.py:55-90` |
| Heuristic-based effect scoring | Working | `src/pob/mastery_optimizer.py:228-310` |
| Mastery optimization integration (both optimizers) | Working | Both optimizer files |
| XML mastery effect read/write | Working | `src/pob/modifier.py:339-418` |

### 1.4 Mastery System - What's Missing

| Gap | Impact | Priority |
|-----|--------|----------|
| Calculator-based evaluation (TODO at line 181) | Suboptimal mastery selection | CRITICAL |
| No multi-mastery interaction modeling | Missing synergy detection | MEDIUM |
| No build-context awareness | Generic scoring, not build-specific | MEDIUM |
| No exhaustive search option | May miss optimal combinations | LOW |
| Limited numeric value parsing | Ignores magnitude differences | LOW |

---

## Part 2: Jewel Optimization Enhancements

### 2.1 Timeless Jewel Modifier Calculation

**Goal**: Understand what stats timeless jewels grant to nodes in their radius

**Current State**:
- `get_timeless_jewel_modifiers()` is a TODO stub
- We parse seed/variant but don't know what they DO to nodes

**Implementation Plan**:

#### Phase 1: PoB TimelessJewelData Integration
```
Location: PathOfBuilding/src/Data/TimelessJewelData/
Files:
  - GloriousVanity.lua (Vaal)
  - LethalPride.lua (Karui)
  - ElegantHubris.lua (Eternal)
  - MilitantFaith.lua (Templar)
  - BrutalRestraint.lua (Maraketh)
```

Each file contains seed → node transformation mappings:
```lua
-- Example structure (simplified)
return {
    [1234] = {  -- seed
        [node_id] = { stat_id, stat_value },
        ...
    },
    ...
}
```

**Tasks**:
1. Create `src/pob/jewel/timeless_data.py`:
   - Parser for TimelessJewelData Lua files
   - Cache parsed data (files are large, ~5-50MB each)
   - Function: `get_node_transformations(jewel_type, seed, node_id) -> List[StatMod]`

2. Update `TimelessJewel` class:
   - Add method: `get_affected_node_stats(node_id) -> Dict[str, float]`
   - Add method: `get_total_radius_value(objective) -> float`

3. Integration with optimizer:
   - Calculate "timeless value" for each potential socket location
   - Consider which allocated nodes fall in radius
   - Score based on transformation quality for objective

**Complexity**: HIGH (large data files, complex parsing)
**Effort**: 3-4 days
**Dependencies**: None

#### Phase 2: Timeless Jewel Socket Optimization

Once we can calculate transformations:
1. For each timeless jewel, evaluate all possible socket locations
2. Calculate total value of transformed nodes at each location
3. Consider pathing cost to reach socket
4. Recommend optimal placement

**Note**: Timeless jewels currently can't move (immutable constraint). This phase would:
- Provide analysis/recommendations for manual adjustment
- OR add optional "allow timeless relocation" flag

---

### 2.2 Radius Jewel Analysis

**Goal**: Optimize placement of radius-affecting unique jewels

**Key Jewels**:
| Jewel | Effect | Optimization Potential |
|-------|--------|----------------------|
| Thread of Hope | Allocate passives in ring, not path | HIGH - pathing bypass |
| Impossible Escape | Allocate passives near keystone | HIGH - pathing bypass |
| Fireborn | Phys→Fire in radius | MEDIUM - element conversion |
| Cold Steel | Phys→Cold in radius | MEDIUM - element conversion |
| Unnatural Instinct | Grants small passives in radius | MEDIUM - socket placement |
| Intuitive Leap | Allocate notables without connection | HIGH - pathing bypass |

**Implementation Plan**:

#### Phase 1: Radius Calculation Infrastructure
```python
# New file: src/pob/jewel/radius_calculator.py

class RadiusCalculator:
    def __init__(self, tree_graph: PassiveTree):
        self.tree = tree_graph
        # Precompute node positions from tree data

    def get_nodes_in_radius(
        self,
        socket_node_id: int,
        radius: JewelRadius
    ) -> Set[int]:
        """Get all nodes within radius of socket."""

    def get_ring_nodes(
        self,
        socket_node_id: int,
        inner_radius: int,
        outer_radius: int
    ) -> Set[int]:
        """Get nodes in ring (for Thread of Hope)."""
```

**Tasks**:
1. Parse node positions from PoB tree data (x, y coordinates)
2. Implement distance calculation between nodes
3. Create radius lookup for each socket
4. Cache results (static per tree version)

#### Phase 2: Thread of Hope Optimization
```python
class ThreadOfHopeOptimizer:
    def find_optimal_socket(
        self,
        build_xml: str,
        allocated_nodes: Set[int],
        objective: str
    ) -> Tuple[int, Set[int], float]:
        """
        Find best socket for Thread of Hope.

        Returns:
            socket_node_id: Best socket location
            ring_nodes: Nodes that can be allocated via ring
            point_savings: Points saved vs normal pathing
        """
```

This enables:
- Identifying which notables become accessible via ring
- Calculating point savings from pathing bypass
- Recommending socket placement

#### Phase 3: Integrate with Optimizer

Add candidates/mutations:
- "Move Thread of Hope to socket X, allocate nodes Y, Z"
- Calculate net improvement (gained stats - lost pathing nodes)

**Complexity**: MEDIUM
**Effort**: 2-3 days
**Dependencies**: Tree position data parsing

---

### 2.3 Cluster Jewel Notable Optimization

**Goal**: Optimize which notables to allocate within cluster jewel subgraphs

**Current State**:
- Cluster nodes are fully protected (never modified)
- We parse notables but don't optimize selection

**Challenge**:
- Cluster nodes use special IDs (>= 65536)
- Subgraph connectivity rules differ from main tree
- Nested clusters add complexity

**Implementation Plan**:

#### Phase 1: Cluster Subgraph Analysis
```python
# New file: src/pob/jewel/cluster_optimizer.py

class ClusterSubgraph:
    def __init__(self, cluster_jewel: ClusterJewel):
        self.jewel = cluster_jewel
        self.socket_node: int  # Entry point
        self.generated_nodes: List[int]  # All nodes in subgraph
        self.notables: List[int]  # Notable node IDs
        self.small_passives: List[int]  # Non-notable nodes
        self.nested_sockets: List[int]  # Sockets for nested clusters

    def get_allocation_options(self) -> List[Set[int]]:
        """Get valid allocation combinations."""
        # Must include path from socket to any allocated notable
        # Must respect point budget
```

#### Phase 2: Cluster Notable Evaluation

For each notable in cluster:
1. Get notable stats from PoB
2. Calculate value for objective
3. Consider point cost (passives needed to reach notable)
4. Rank notables by efficiency

#### Phase 3: Protected Node Relaxation

Current: All cluster nodes protected
Proposed: Protect socket + allocated nodes, allow reallocation within subgraph

```python
# In JewelRegistry.get_protected_nodes()
if cluster_optimization_enabled:
    # Only protect the socket entry point
    protected.add(cluster.socket_node_id)
    # Allow optimizer to reallocate within subgraph
else:
    # Current behavior: protect everything
    protected.update(cluster.generated_nodes)
```

**Complexity**: HIGH (subgraph connectivity, nested clusters)
**Effort**: 4-5 days
**Dependencies**: Cluster node position/connectivity data

---

### 2.4 Jewel Placement Score System

**Goal**: Unified scoring for jewel placement decisions

```python
@dataclass
class JewelPlacementScore:
    socket_node_id: int
    jewel: BaseJewel

    # Costs
    pathing_cost: int  # Points to reach socket
    opportunity_cost: float  # Value of nodes used for pathing

    # Benefits
    direct_value: float  # Stats from jewel itself
    radius_value: float  # Value from radius effects (if applicable)
    transformation_value: float  # Value from node transformations (timeless)

    # Net
    @property
    def net_value(self) -> float:
        return (self.direct_value + self.radius_value + self.transformation_value
                - self.opportunity_cost)

    @property
    def efficiency(self) -> float:
        """Value per point spent."""
        if self.pathing_cost == 0:
            return float('inf')
        return self.net_value / self.pathing_cost
```

This enables comparing:
- Different sockets for same jewel
- Different jewels for same socket
- Trade-offs between jewel value and pathing cost

---

## Part 3: Mastery Optimization Enhancements

### 3.1 Calculator-Based Mastery Evaluation

**Goal**: Replace heuristics with actual build calculations

**Current State** (line 181 TODO):
```python
# TODO: Implement once we integrate with RelativeCalculator
# For now, fall back to heuristics
return self._evaluate_effects_with_heuristics(...)
```

**Implementation Plan**:

#### Phase 1: Single Mastery Evaluation
```python
def _evaluate_effect_with_calculator(
    self,
    base_xml: str,
    mastery_node_id: int,
    effect_id: int,
    calculator: RelativeCalculator,
    objective: str
) -> float:
    """
    Evaluate a single mastery effect by calculating actual build impact.
    """
    # 1. Create modified XML with this mastery effect
    modified_xml = modify_passive_tree_nodes(
        base_xml,
        nodes_to_add=set(),
        nodes_to_remove=set(),
        mastery_effects_to_add={mastery_node_id: effect_id}
    )

    # 2. Calculate build stats
    result = calculator.evaluate_modification(base_xml, modified_xml)

    # 3. Return objective-appropriate score
    if objective == 'dps':
        return result.dps_change_percent
    elif objective == 'life':
        return result.life_change_percent
    elif objective == 'ehp':
        return result.ehp_change_percent
    else:  # balanced
        return (result.dps_change_percent +
                result.life_change_percent +
                result.ehp_change_percent) / 3
```

#### Phase 2: Batch Mastery Evaluation

For builds with 10-20 masteries, evaluating each option individually is expensive:
- 15 masteries × 5 options = 75 evaluations
- At ~0.5s per eval = 37.5 seconds just for masteries

**Solution**: Use BatchCalculator for parallel evaluation

```python
def select_best_mastery_effects_batch(
    self,
    base_xml: str,
    allocated_nodes: Set[int],
    current_effects: Dict[int, int],
    objective: str,
    batch_calculator: BatchCalculator
) -> Dict[int, int]:
    """
    Evaluate all mastery options using batch evaluation.
    """
    # Build all modifications
    modifications = {}
    effect_map = {}  # Track which modification corresponds to which effect

    for node_id in allocated_nodes:
        if not self.mastery_db.is_mastery_node(node_id):
            continue
        mastery = self.mastery_db.get_mastery(node_id)
        for effect in mastery.available_effects:
            key = f"mastery_{node_id}_{effect.effect_id}"
            modifications[key] = modify_passive_tree_nodes(
                base_xml,
                mastery_effects_to_add={node_id: effect.effect_id}
            )
            effect_map[key] = (node_id, effect.effect_id)

    # Batch evaluate
    results = batch_calculator.evaluate_batch(base_xml, modifications)

    # Find best effect for each mastery
    best_effects = {}
    for node_id in allocated_nodes:
        if not self.mastery_db.is_mastery_node(node_id):
            continue
        best_score = float('-inf')
        best_effect_id = current_effects.get(node_id)

        mastery = self.mastery_db.get_mastery(node_id)
        for effect in mastery.available_effects:
            key = f"mastery_{node_id}_{effect.effect_id}"
            if key in results:
                score = get_objective_score(results[key], objective)
                if score > best_score:
                    best_score = score
                    best_effect_id = effect.effect_id

        if best_effect_id:
            best_effects[node_id] = best_effect_id

    return best_effects
```

**Complexity**: MEDIUM
**Effort**: 2-3 days
**Dependencies**: BatchCalculator (already implemented)

---

### 3.2 Exhaustive Mastery Search Mode

**Goal**: Option to try ALL mastery combinations (expensive but thorough)

For small numbers of masteries, exhaustive search is feasible:
- 5 masteries × 5 options each = 5^5 = 3,125 combinations
- 10 masteries = 9.7 million combinations (too many)

**Implementation**:
```python
def exhaustive_mastery_search(
    self,
    base_xml: str,
    mastery_nodes: List[int],
    objective: str,
    max_combinations: int = 10000
) -> Dict[int, int]:
    """
    Try all mastery combinations up to max_combinations.
    Falls back to greedy if too many combinations.
    """
    # Calculate total combinations
    total = 1
    for node_id in mastery_nodes:
        mastery = self.mastery_db.get_mastery(node_id)
        total *= len(mastery.available_effects)

    if total > max_combinations:
        logger.warning(f"Too many combinations ({total}), using greedy")
        return self.select_best_mastery_effects(...)

    # Generate all combinations
    all_options = []
    for node_id in mastery_nodes:
        mastery = self.mastery_db.get_mastery(node_id)
        all_options.append([
            (node_id, e.effect_id)
            for e in mastery.available_effects
        ])

    # Evaluate all combinations
    best_combo = None
    best_score = float('-inf')

    for combo in itertools.product(*all_options):
        effects = dict(combo)
        modified_xml = modify_passive_tree_nodes(
            base_xml,
            mastery_effects_to_add=effects
        )
        score = calculator.evaluate(modified_xml, objective)
        if score > best_score:
            best_score = score
            best_combo = effects

    return best_combo
```

**Use Case**: Final polish pass after main optimization

---

### 3.3 Mastery Synergy Detection

**Goal**: Identify masteries that work well together

Some masteries have synergies:
- "+1 to maximum totems" + "totems deal increased damage"
- "Critical strike chance" + "critical strike multiplier"
- "Life regeneration" + "% of life regenerated on kill"

**Implementation**:
```python
@dataclass
class MasterySynergy:
    effect_ids: Tuple[int, int]
    synergy_type: str  # 'additive', 'multiplicative', 'enabling'
    combined_value: float  # Value when both present
    individual_sum: float  # Sum of individual values
    synergy_bonus: float  # combined - individual_sum

class MasterySynergyDetector:
    def detect_synergies(
        self,
        build_xml: str,
        mastery_effects: Dict[int, int],
        calculator: RelativeCalculator
    ) -> List[MasterySynergy]:
        """
        Detect synergies between allocated mastery effects.
        """
        synergies = []
        effects = list(mastery_effects.items())

        for i, (node1, effect1) in enumerate(effects):
            for node2, effect2 in effects[i+1:]:
                # Test each individually
                val1 = evaluate_single(node1, effect1)
                val2 = evaluate_single(node2, effect2)

                # Test combined
                combined = evaluate_both(node1, effect1, node2, effect2)

                # Check for synergy
                if combined > val1 + val2 + SYNERGY_THRESHOLD:
                    synergies.append(MasterySynergy(
                        effect_ids=(effect1, effect2),
                        synergy_type='multiplicative',
                        combined_value=combined,
                        individual_sum=val1 + val2,
                        synergy_bonus=combined - (val1 + val2)
                    ))

        return synergies
```

**Complexity**: MEDIUM
**Effort**: 2 days
**Use Case**: Reporting, guiding mastery selection

---

### 3.4 Build-Context Mastery Scoring

**Goal**: Use build information to improve heuristic scoring

Current heuristics are generic. We could enhance them with:
- **Ascendancy awareness**: Slayer benefits from leech, Pathfinder from flask
- **Skill type detection**: Spell vs Attack, Melee vs Ranged
- **Damage type detection**: Physical, Elemental, Chaos, DoT
- **Defense style**: Life, ES, Hybrid, Evasion, Armor

```python
@dataclass
class BuildContext:
    primary_damage_type: str  # 'physical', 'fire', 'cold', 'lightning', 'chaos'
    damage_style: str  # 'hit', 'dot', 'minion'
    attack_or_spell: str  # 'attack', 'spell', 'both'
    defense_style: str  # 'life', 'es', 'hybrid', 'evasion', 'armor'
    ascendancy: str  # 'Slayer', 'Necromancer', etc.
    key_mechanics: Set[str]  # 'totems', 'brands', 'traps', 'mines', etc.

    @classmethod
    def from_build_xml(cls, xml: str) -> "BuildContext":
        """Extract build context from PoB XML."""
        # Parse ascendancy from Spec element
        # Analyze skills for damage/attack types
        # Check keystones for defense style
        # Identify key mechanics from gems
```

Then enhance scoring:
```python
def _score_effect_contextual(
    self,
    effect: MasteryEffect,
    objective: str,
    context: BuildContext
) -> float:
    base_score = self._score_effect(effect, objective)

    # Boost relevant stats
    if context.primary_damage_type in effect.get_all_stats_text().lower():
        base_score *= 1.5

    if context.attack_or_spell == 'attack' and 'attack' in effect.stats_text:
        base_score *= 1.3

    # Penalize irrelevant stats
    if context.defense_style == 'es' and 'life' in effect.stats_text:
        base_score *= 0.5

    return base_score
```

**Complexity**: MEDIUM
**Effort**: 2-3 days

---

## Part 4: Implementation Priorities

### Priority Matrix

| Feature | Impact | Effort | Priority | Dependencies |
|---------|--------|--------|----------|--------------|
| Calculator-based mastery evaluation | CRITICAL | 2-3 days | P0 | BatchCalculator |
| Radius calculation infrastructure | HIGH | 2 days | P1 | Tree position data |
| Thread of Hope optimization | HIGH | 2 days | P1 | Radius calc |
| Timeless jewel data parsing | HIGH | 3-4 days | P1 | None |
| Cluster notable optimization | MEDIUM | 4-5 days | P2 | Subgraph logic |
| Mastery synergy detection | MEDIUM | 2 days | P2 | Calculator mastery |
| Build-context scoring | MEDIUM | 2-3 days | P3 | None |
| Exhaustive mastery search | LOW | 1 day | P3 | Calculator mastery |
| Jewel placement score system | MEDIUM | 1 day | P3 | Radius calc |

### Recommended Implementation Order

#### Sprint 1: Core Mastery Improvements (5-7 days)
1. Calculator-based mastery evaluation
2. Batch mastery evaluation integration
3. Update MasteryOptimizer to use new methods
4. Tests and validation

#### Sprint 2: Radius Infrastructure (4-5 days)
1. Parse tree node positions from PoB
2. Implement RadiusCalculator
3. Thread of Hope socket analysis
4. Integrate with optimizer candidates

#### Sprint 3: Timeless Jewel Analysis (5-6 days)
1. Parse TimelessJewelData files
2. Implement transformation lookup
3. Calculate timeless jewel value per socket
4. Add analysis/recommendation output

#### Sprint 4: Cluster & Polish (5-7 days)
1. Cluster subgraph modeling
2. Protected node relaxation (optional cluster optimization)
3. Mastery synergy detection
4. Build-context scoring
5. Documentation and tests

---

## Part 5: Technical Specifications

### 5.1 New Files to Create

```
src/pob/jewel/
  ├── radius_calculator.py      # Node radius calculations
  ├── timeless_data.py          # TimelessJewelData parsing
  ├── cluster_optimizer.py      # Cluster subgraph optimization
  └── thread_of_hope.py         # Thread of Hope specific logic

src/pob/
  └── build_context.py          # Build context extraction

tests/
  ├── test_radius_calculator.py
  ├── test_timeless_data.py
  ├── test_cluster_optimizer.py
  └── test_mastery_calculator.py
```

### 5.2 Files to Modify

```
src/pob/mastery_optimizer.py
  - Add calculator-based evaluation
  - Add batch evaluation support
  - Add synergy detection
  - Add build-context scoring

src/pob/jewel/registry.py
  - Add cluster optimization flag
  - Modify protected nodes logic

src/optimizer/tree_optimizer.py
  - Integrate new mastery evaluation
  - Add Thread of Hope candidates
  - Add cluster reallocation candidates

src/optimizer/genetic_optimizer.py
  - Integrate new mastery evaluation
  - Add radius-aware jewel mutations
```

### 5.3 Data Dependencies

| Data | Source | Size | Caching Strategy |
|------|--------|------|------------------|
| Tree node positions | `PathOfBuilding/src/TreeData/*/tree.lua` | ~2MB | Parse once, cache in memory |
| Timeless transformations | `PathOfBuilding/src/Data/TimelessJewelData/` | ~50MB total | Lazy load per jewel type |
| Mastery effects | `PathOfBuilding/src/TreeData/*/tree.lua` | ~500KB | Already cached via MasteryDatabase |
| Cluster notables | PoB calculation | N/A | Request from PoB per build |

### 5.4 Performance Considerations

| Operation | Current | Target | Strategy |
|-----------|---------|--------|----------|
| Mastery evaluation (15 masteries) | ~0.5s heuristic | ~15s calculator | Batch evaluation, parallel |
| Radius calculation | N/A | <100ms | Precompute, cache |
| Timeless lookup | N/A | <10ms | Hash table |
| Full optimization run | ~10 min | ~12 min | Accept slight increase for quality |

---

## Part 6: Testing Strategy

### 6.1 Unit Tests

```python
# test_mastery_calculator.py
def test_calculator_beats_heuristics():
    """Verify calculator finds better masteries than heuristics."""

def test_batch_matches_sequential():
    """Verify batch evaluation matches sequential results."""

# test_radius_calculator.py
def test_radius_node_count():
    """Verify correct nodes returned for each radius size."""

def test_thread_of_hope_ring():
    """Verify ring calculation for Thread of Hope."""

# test_timeless_data.py
def test_parse_glorious_vanity():
    """Verify Glorious Vanity data parsing."""

def test_node_transformation_lookup():
    """Verify transformation lookup by seed."""
```

### 6.2 Integration Tests

```python
def test_full_optimization_with_new_mastery():
    """Run full optimization with calculator masteries."""

def test_thread_of_hope_build():
    """Optimize a build with Thread of Hope."""

def test_timeless_jewel_build():
    """Optimize a build with timeless jewels."""
```

### 6.3 Benchmark Tests

```python
def test_mastery_evaluation_performance():
    """Benchmark mastery evaluation time."""

def test_radius_calculation_performance():
    """Benchmark radius calculations."""
```

---

## Part 7: Risks and Mitigations

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| PoB data format changes | HIGH | LOW | Version check, fallback to heuristics |
| Timeless data too large for memory | MEDIUM | LOW | Lazy loading, LRU cache |
| Calculator evaluation too slow | HIGH | MEDIUM | Batch evaluation, caching |
| Cluster optimization breaks builds | HIGH | MEDIUM | Extensive testing, opt-in flag |
| Tree position data parsing fails | MEDIUM | LOW | Fallback to grid approximation |

---

## Part 8: Success Metrics

### Quantitative
- Mastery selection quality: 20%+ improvement over heuristics (measured on test builds)
- Thread of Hope placement: Correctly identifies optimal socket in 90%+ of cases
- Optimization time: <20% increase from v0.7

### Qualitative
- Users report better mastery selections
- Thread of Hope/radius jewel recommendations match expert opinion
- Timeless jewel analysis provides useful insights

---

## Appendix: Reference Implementation Sketches

### A.1 Calculator-Based Mastery Selection (Core Change)

```python
# In mastery_optimizer.py, replacing the TODO

def select_best_mastery_effects(
    self,
    allocated_nodes: Set[int],
    current_mastery_effects: Dict[int, int],
    objective: str = 'dps',
    calculator: Optional[RelativeCalculator] = None,
    batch_calculator: Optional[BatchCalculator] = None,
    base_xml: Optional[str] = None,
) -> Dict[int, int]:
    """Select best mastery effects for allocated mastery nodes."""

    mastery_nodes = [
        n for n in allocated_nodes
        if self.mastery_db.is_mastery_node(n)
    ]

    if not mastery_nodes:
        return {}

    # Use calculator if available
    if batch_calculator and base_xml:
        return self._evaluate_effects_with_batch_calculator(
            base_xml, mastery_nodes, current_mastery_effects,
            objective, batch_calculator
        )
    elif calculator and base_xml:
        return self._evaluate_effects_with_calculator(
            base_xml, mastery_nodes, current_mastery_effects,
            objective, calculator
        )
    else:
        # Fallback to heuristics
        return self._evaluate_effects_with_heuristics(
            mastery_nodes, objective
        )
```

### A.2 Radius Calculator Core

```python
# New file: src/pob/jewel/radius_calculator.py

from typing import Dict, Set, Tuple
from dataclasses import dataclass
import math

@dataclass
class NodePosition:
    node_id: int
    x: float
    y: float
    orbit: int  # Distance from center

class RadiusCalculator:
    # Radius thresholds (approximate node distance units)
    SMALL_RADIUS = 800
    MEDIUM_RADIUS = 1200
    LARGE_RADIUS = 1800

    def __init__(self, tree_data_path: str):
        self.positions: Dict[int, NodePosition] = {}
        self._load_positions(tree_data_path)
        self._socket_radius_cache: Dict[Tuple[int, int], Set[int]] = {}

    def _load_positions(self, path: str):
        """Parse node positions from tree.lua."""
        # Extract ["x"] and ["y"] from node definitions
        pass

    def distance(self, node1: int, node2: int) -> float:
        """Calculate distance between two nodes."""
        p1 = self.positions[node1]
        p2 = self.positions[node2]
        return math.sqrt((p1.x - p2.x)**2 + (p1.y - p2.y)**2)

    def get_nodes_in_radius(
        self,
        socket_id: int,
        radius: int
    ) -> Set[int]:
        """Get all nodes within radius of socket."""
        cache_key = (socket_id, radius)
        if cache_key in self._socket_radius_cache:
            return self._socket_radius_cache[cache_key]

        result = set()
        socket_pos = self.positions[socket_id]

        for node_id, pos in self.positions.items():
            if self.distance(socket_id, node_id) <= radius:
                result.add(node_id)

        self._socket_radius_cache[cache_key] = result
        return result
```

---

*Document created: January 2025*
*Target release: v0.8.0*
